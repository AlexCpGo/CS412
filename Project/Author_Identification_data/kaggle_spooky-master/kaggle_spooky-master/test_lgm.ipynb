{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19579, 1866)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(\"./input/train.csv\")\n",
    "author_mapping_dict = {'EAP':0, 'HPL':1, 'MWS':2}\n",
    "train_y = train_df['author'].map(author_mapping_dict)\n",
    "train_Y = train_y\n",
    "\n",
    "\n",
    "with open('feat.pkl','rb') as fin:\n",
    "    f_train_X,f_test_X = pickle.load(fin)\n",
    "print(f_train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "import lightgbm as lgb\n",
    "\n",
    "def cv_test(k_cnt=3, s_flag = False):\n",
    "    rnd = 420\n",
    "    if s_flag:\n",
    "        kf = StratifiedKFold(n_splits=k_cnt, shuffle=True, random_state=rnd)\n",
    "    else:\n",
    "        kf = KFold(n_splits=k_cnt, shuffle=True, random_state=rnd)\n",
    "    test_pred = None\n",
    "    weighted_test_pred = None\n",
    "    org_train_pred = None\n",
    "    avg_k_score = 0\n",
    "    reverse_score = 0\n",
    "    best_loss = 100\n",
    "    best_single_pred = None\n",
    "    for train_index, test_index in kf.split(f_train_X,train_Y):\n",
    "        X_train, X_test = f_train_X[train_index], f_train_X[test_index]\n",
    "        y_train, y_test = train_Y[train_index], train_Y[test_index]\n",
    "        \n",
    "        dtx = lgb.Dataset(X_train, label=y_train)\n",
    "        dtv = lgb.Dataset(X_test, label=y_test)\n",
    "        \n",
    "        params = {\n",
    "            'learning_rate':0.04,\n",
    "            'max_depth':4,\n",
    "            'objective':'multiclass',\n",
    "            'num_class':3,\n",
    "            'metric':{'multi_logloss'},\n",
    "            'feature_fraction':0.8,\n",
    "            'bagging_fraction':0.7,\n",
    "            'lambda_l2':1.0\n",
    "        }\n",
    "        \n",
    "        m = lgb.train(params, train_set=dtx, valid_sets=dtv, valid_names=['val'],\n",
    "                      num_boost_round=1000,\n",
    "                      early_stopping_rounds=50,\n",
    "                      verbose_eval=50)\n",
    "        \n",
    "        # get res\n",
    "        train_pred = m.predict(X_train)\n",
    "        print(train_pred.shape,y_train.shape)\n",
    "        valid_pred = m.predict(X_test)\n",
    "        tmp_train_pred = m.predict(f_train_X)\n",
    "        \n",
    "        # cal score\n",
    "        train_score = log_loss(y_train,train_pred)\n",
    "        valid_score = log_loss(y_test,valid_pred)\n",
    "        print('train log loss',train_score,'valid log loss',valid_score)\n",
    "        avg_k_score += valid_score\n",
    "        rev_valid_score = 1.0/valid_score # use for weighted\n",
    "        reverse_score += rev_valid_score # sum\n",
    "        print('rev',rev_valid_score)\n",
    "        \n",
    "        if test_pred is None:\n",
    "            test_pred = m.predict(f_test_X)\n",
    "            weighted_test_pred = test_pred*rev_valid_score\n",
    "            org_train_pred = tmp_train_pred\n",
    "            best_loss = valid_score\n",
    "            best_single_pred = test_pred\n",
    "        else:\n",
    "            curr_pred = m.predict(f_test_X)\n",
    "            test_pred += curr_pred\n",
    "            weighted_test_pred += curr_pred*rev_valid_score # fix bug here\n",
    "            org_train_pred += tmp_train_pred\n",
    "            # find better single model\n",
    "            if valid_score < best_loss:\n",
    "                print('BETTER')\n",
    "                best_loss = valid_score\n",
    "                best_single_pred = curr_pred\n",
    "\n",
    "    # avg\n",
    "    test_pred = test_pred / k_cnt\n",
    "    print(test_pred.shape)\n",
    "    print(test_pred[:5])\n",
    "    org_train_pred = org_train_pred / k_cnt\n",
    "    avg_k_score = avg_k_score/k_cnt\n",
    "\n",
    "\n",
    "    submiss=pd.read_csv(\"./input/sample_submission.csv\")\n",
    "    submiss['EAP']=test_pred[:,0]\n",
    "    submiss['HPL']=test_pred[:,1]\n",
    "    submiss['MWS']=test_pred[:,2]\n",
    "    submiss.to_csv(\"results/lgb_res_{}_{}.csv\".format(k_cnt, s_flag),index=False)\n",
    "    print(submiss.head(5))\n",
    "    print('--------------')\n",
    "    print(reverse_score)\n",
    "    # weigthed\n",
    "    submiss=pd.read_csv(\"./input/sample_submission.csv\")\n",
    "    weighted_test_pred = weighted_test_pred / reverse_score\n",
    "    weighted_test_pred = np.round(weighted_test_pred,4)\n",
    "    submiss['EAP']=weighted_test_pred[:,0]\n",
    "    submiss['HPL']=weighted_test_pred[:,1]\n",
    "    submiss['MWS']=weighted_test_pred[:,2]\n",
    "    submiss.to_csv(\"results/weighted_lgb_res_{}_{}.csv\".format(k_cnt, s_flag),index=False)\n",
    "    print(submiss.head(5))\n",
    "    print('---------------')\n",
    "    # best single\n",
    "    submiss=pd.read_csv(\"./input/sample_submission.csv\")\n",
    "    weighted_test_pred = np.round(best_single_pred,4)\n",
    "    submiss['EAP']=weighted_test_pred[:,0]\n",
    "    submiss['HPL']=weighted_test_pred[:,1]\n",
    "    submiss['MWS']=weighted_test_pred[:,2]\n",
    "    submiss.to_csv(\"results/single_lgb_res_{}_{}.csv\".format(k_cnt, s_flag),index=False)\n",
    "    print(submiss.head(5))\n",
    "    print('---------------')\n",
    "    \n",
    "    # train log loss\n",
    "    print('local average valid loss',avg_k_score)\n",
    "    print('train log loss', log_loss(train_Y,org_train_pred))\n",
    "    \n",
    "print('def done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tval's multi_logloss: 0.360099\n",
      "[100]\tval's multi_logloss: 0.284331\n",
      "[150]\tval's multi_logloss: 0.269445\n",
      "[200]\tval's multi_logloss: 0.264686\n",
      "[250]\tval's multi_logloss: 0.262473\n",
      "[300]\tval's multi_logloss: 0.261332\n",
      "[350]\tval's multi_logloss: 0.260809\n",
      "[400]\tval's multi_logloss: 0.261061\n",
      "Early stopping, best iteration is:\n",
      "[357]\tval's multi_logloss: 0.260706\n",
      "(15663, 3) (15663,)\n",
      "train log loss 0.152493228338 valid log loss 0.260819032209\n",
      "rev 3.83407603168\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tval's multi_logloss: 0.365961\n",
      "[100]\tval's multi_logloss: 0.291184\n",
      "[150]\tval's multi_logloss: 0.276315\n",
      "[200]\tval's multi_logloss: 0.269672\n",
      "[250]\tval's multi_logloss: 0.267424\n",
      "[300]\tval's multi_logloss: 0.265944\n",
      "[350]\tval's multi_logloss: 0.265218\n",
      "[400]\tval's multi_logloss: 0.264875\n",
      "[450]\tval's multi_logloss: 0.264679\n",
      "[500]\tval's multi_logloss: 0.265054\n",
      "Early stopping, best iteration is:\n",
      "[463]\tval's multi_logloss: 0.264676\n",
      "(15663, 3) (15663,)\n",
      "train log loss 0.135334683342 valid log loss 0.264797567803\n",
      "rev 3.77646973233\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tval's multi_logloss: 0.364308\n",
      "[100]\tval's multi_logloss: 0.287075\n",
      "[150]\tval's multi_logloss: 0.271669\n",
      "[200]\tval's multi_logloss: 0.265781\n",
      "[250]\tval's multi_logloss: 0.263257\n",
      "[300]\tval's multi_logloss: 0.261482\n",
      "[350]\tval's multi_logloss: 0.260122\n",
      "[400]\tval's multi_logloss: 0.259821\n",
      "[450]\tval's multi_logloss: 0.259687\n",
      "[500]\tval's multi_logloss: 0.259606\n",
      "[550]\tval's multi_logloss: 0.25957\n",
      "Early stopping, best iteration is:\n",
      "[524]\tval's multi_logloss: 0.259454\n",
      "(15663, 3) (15663,)\n",
      "train log loss 0.124358683439 valid log loss 0.259459747012\n",
      "rev 3.8541623952\n",
      "BETTER\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tval's multi_logloss: 0.365512\n",
      "[100]\tval's multi_logloss: 0.289424\n",
      "[150]\tval's multi_logloss: 0.27438\n",
      "[200]\tval's multi_logloss: 0.267062\n",
      "[250]\tval's multi_logloss: 0.264007\n",
      "[300]\tval's multi_logloss: 0.262329\n",
      "[350]\tval's multi_logloss: 0.261382\n",
      "[400]\tval's multi_logloss: 0.260301\n",
      "[450]\tval's multi_logloss: 0.260072\n",
      "[500]\tval's multi_logloss: 0.259947\n",
      "[550]\tval's multi_logloss: 0.259833\n",
      "Early stopping, best iteration is:\n",
      "[512]\tval's multi_logloss: 0.259733\n",
      "(15663, 3) (15663,)\n",
      "train log loss 0.124088941112 valid log loss 0.259799830811\n",
      "rev 3.84911721028\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\tval's multi_logloss: 0.360665\n",
      "[100]\tval's multi_logloss: 0.28251\n",
      "[150]\tval's multi_logloss: 0.265148\n",
      "[200]\tval's multi_logloss: 0.257872\n",
      "[250]\tval's multi_logloss: 0.254371\n",
      "[300]\tval's multi_logloss: 0.252201\n",
      "[350]\tval's multi_logloss: 0.251019\n",
      "[400]\tval's multi_logloss: 0.250464\n",
      "[450]\tval's multi_logloss: 0.249956\n",
      "[500]\tval's multi_logloss: 0.249822\n",
      "[550]\tval's multi_logloss: 0.249537\n",
      "[600]\tval's multi_logloss: 0.249419\n",
      "[650]\tval's multi_logloss: 0.249194\n",
      "[700]\tval's multi_logloss: 0.249303\n",
      "Early stopping, best iteration is:\n",
      "[667]\tval's multi_logloss: 0.249077\n",
      "(15664, 3) (15664,)\n",
      "train log loss 0.106908341109 valid log loss 0.248952181345\n",
      "rev 4.01683566137\n",
      "BETTER\n",
      "(8392, 3)\n",
      "[[  1.12812243e-02   2.54336264e-03   9.86175413e-01]\n",
      " [  9.98963975e-01   6.61197597e-04   3.74826963e-04]\n",
      " [  2.58635655e-03   9.96627986e-01   7.85657253e-04]\n",
      " [  8.79606343e-01   1.17016914e-01   3.37674355e-03]\n",
      " [  7.56893674e-01   1.62866196e-01   8.02401299e-02]]\n",
      "        id       EAP       HPL       MWS\n",
      "0  id02310  0.011281  0.002543  0.986175\n",
      "1  id24541  0.998964  0.000661  0.000375\n",
      "2  id00134  0.002586  0.996628  0.000786\n",
      "3  id27757  0.879606  0.117017  0.003377\n",
      "4  id04081  0.756894  0.162866  0.080240\n",
      "--------------\n",
      "19.3306610308\n",
      "        id     EAP     HPL     MWS\n",
      "0  id02310  0.0113  0.0025  0.9862\n",
      "1  id24541  0.9990  0.0007  0.0004\n",
      "2  id00134  0.0026  0.9966  0.0008\n",
      "3  id27757  0.8795  0.1172  0.0034\n",
      "4  id04081  0.7573  0.1624  0.0803\n",
      "---------------\n",
      "        id     EAP     HPL     MWS\n",
      "0  id02310  0.0072  0.0029  0.9899\n",
      "1  id24541  0.9988  0.0009  0.0002\n",
      "2  id00134  0.0025  0.9963  0.0012\n",
      "3  id27757  0.8503  0.1463  0.0034\n",
      "4  id04081  0.7726  0.1366  0.0907\n",
      "---------------\n",
      "local average valid loss 0.258765671836\n",
      "train log loss 0.143251529759\n"
     ]
    }
   ],
   "source": [
    "cv_test(5,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv_test(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
